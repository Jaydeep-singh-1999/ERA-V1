# Assignment S6 ERA-V1

## Part 1

Assignment Overview:
- Rewrite the whole Excel sheet showing backpropagation.
- Explain each major step and write it on GitHub.
- Use the same values for all variables as used in the class.
- Include a screenshot of the Excel sheet in the readme file.
- Upload the Excel file to GitHub.

### Steps to Complete Part 1:

1. Excel Sheet: Rewrite the Excel sheet that demonstrates the backpropagation process. Ensure that the initial weights, biases, inputs, activation functions, and calculations for the forward and backward passes are accurately represented.

2. Explanation: Provide a detailed explanation of each major step involved in the backpropagation process. Break down the calculations, formulas, and concepts used in the Excel sheet. This will help in understanding the flow of information during training.

3. Screenshot: Take a screenshot of the completed Excel sheet. The screenshot should capture the entire sheet, including all the cells and formulas. This screenshot will be included in the README file.

4. GitHub Repository: Create a public GitHub repository for this assignment. Inside the repository, create a folder named "S6" and add the Excel file to this folder. Make sure the Excel file is accessible and downloadable.

5. README.md File: Create a README.md file in the repository root directory. The README file should contain the following sections:

   - Introduction: Provide an overview of the assignment and its requirements.
   - Explanation: Describe the backpropagation process and its major steps. Use bullet points, code snippets, or mathematical equations to explain the concepts.
   - Screenshot: Embed the screenshot of the Excel sheet in the README file using the Markdown syntax.
   - Excel File: Provide a link to download the Excel file from the "S6" folder in the GitHub repository.

6. Submit Details: Submit the details of the completed assignment in the S6 - Assignment QnA section.

## Part 2

Assignment Overview:
- Consider various points covered in the last 5 lectures.
- Aim to achieve 99.4% validation accuracy and meet specific requirements.
- Modify the provided code to integrate different techniques.
- Upload the code to GitHub.

The points covered in the lectures include:
- Number of layers
- MaxPooling
- 1x1 Convolutions
- 3x3 Convolutions
- Receptive Field
- SoftMax
- Learning Rate
- Kernels and determining the number of kernels
- Batch Normalization
- Image Normalization
- Position of MaxPooling
- Concept of Transition Layers
- Position of Transition Layer
- DropOut
- Identifying overfitting
- Distance of MaxPooling from Prediction
- Distance of Batch Normalization from Prediction
- Choosing larger kernels or alternative approaches
- Early identification of network performance issues
- Batch Size and its effects

To complete Part 2, follow these steps:

1. Code Reference: Refer to the provided code in the COLABLINK to understand how to integrate different techniques like Dropout and Batch Normalization. Do not directly copy the architecture, but focus on learning how to integrate the mentioned techniques effectively.

2. Modification: Modify the provided code to achieve the assignment requirements. Aim for a validation accuracy of 99.4% or higher, less than 20k parameters, and complete the training in less than 20 epochs. Incorporate techniques such as Batch Normalization (BN), Dropout, and optionally a Fully Connected layer or Global Average Pooling (GAP).

3. Documentation: Document the modifications made to the code and explain the reasoning behind each change. Describe how each technique is integrated and its impact on the network's performance.

4. GitHub Repository: Create a public GitHub repository for this assignment. Upload the modified code to the repository, ensuring


## Part 2 SOLUTION:


